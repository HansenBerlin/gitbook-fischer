# 2.3 Modellierung

Die im ETL-Prozess vorbereiteten Datensätze sollen nun im Folgenden in ein Data-Warehosue konformes Format überführt werden.&#x20;

Grundsätzlich kann in zwei Unternehmensdomänen 'Kauf neuer Immobilien' und 'Verwaltung eigener Bestandsimmobilien' unterschieden werden. Aufgrund verschiedener Scopes dieser Domänen und aufgrund verschiedener Datenquellen (intern / extern) wurde sich dazu entschieden, diese in eine jeweils eigene Faktentabelle zu überführen. Das Datenbankschema entspricht also aufgrund mehrerer Faktentabellen einem Galaxy-Schema:

![](../../.gitbook/assets/fischer\_dwh.png)

Die Überführung der ETL-Ergebnisse wurde mittels Python Code vorgenommen. \
Dazu werden die kategorialen Spalten jedes Dataframes in eine Liste geschrieben (Zeile 1, 2). Um nun die Dimensionstabellen zu erstellen, wird die Methode create\_dim\_tables genutzt. Diese bekommt die dazugehörige Faktentabelle fact\_table und die vorher definierten kategorialen Spalten als Parameter übergeben. \
Um die Dimensionstabellen abzuspiechern wird in Zeile 4 ein globales, leeres Dictionary deklariert, welches dann in der create\_dim\_tables Methode mit Dataframes gefüllt wird. Als key dient der Spaltenname. \
Die Dataframes beinhalten zwei spalten: 'id' und 'name'.&#x20;

{% code lineNumbers="true" %}
```python
immoscout_buy_categorical = ['condition']
immoscout_rent_categorical = ['condition', 'interiorQual', 'typeOfFlat', 'heatingType']

dim_tables = {}

def append_to_dataframe(df: pd.DataFrame, df_to_append: pd.DataFrame, on: str):
    if len(pd.DataFrame(df)) == 0:
        df = pd.concat([df, df_to_append])
        return df
    return df.merge(df_to_append, on=on, how='outer')


def create_dim_tables(fact_table: pd.DataFrame, categorical_columns: list[str]):
    global dim_tables
    for column in categorical_columns:
        if column not in dim_tables.keys():
            dim_tables[column] = pd.DataFrame(columns=['id', 'name'])
        unique_values = pd.Series(fact_table[column]).unique()
        for value in unique_values:
            new_dimension = pd.DataFrame(columns=['name'], data=[value])
            dim_tables[column] = append_to_dataframe(dim_tables[column], new_dimension, 'name')
            dim_tables[column]['id'] = dim_tables[column].index + 1
            
immoscout_rent = immoscout_rent.merge(rent_aggregates, on='id')
immoscout_buy = immoscout_buy.merge(buy_score, on='id')
```
{% endcode %}

Um nun die die Werte in den kategorialen Spalten mit dem fremdschlüssel der Dimensionstabelle zu ersetzten wird folgende methode verwendet und folgendermaßen angewandt:

```python
def replace_with_foreign_key(value: str, col: str):
    global dim_tables
    if str(value) == 'nan' or str(value) == '':
        value = 'no_information'
    row: pd.DataFrame = dim_tables[col].loc[dim_tables[col]['name'] == value]
    return row['id'].values[0]
    
for column in immoscout_buy_categorical:
    immoscout_buy[column] = immoscout_buy[column].apply(lambda x: replace_with_foreign_key(x, column))

for column in immoscout_rent_categorical:
    immoscout_rent[column] = immoscout_rent[column].apply(lambda x: replace_with_foreign_key(x, column))
```

Schlussendlich werden die Dataframes wieder als .csv abgespeichert und in eine Datenbank importiert. Die Schlüssel und Verweise werden händisch im DBMS konfiguriert.

Das Datenbankschema und der Quellcode ist den Anlagen zu entnehmen.
