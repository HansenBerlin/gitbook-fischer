# 2.2 ETL Prozess

Fokus: Transform (Filterung, Harmonisierung, Aggregation, Anreicherung) und kurz Load (eigene API, ohne Code, den dann im Anhang)

## immoscout\_rent.csv

### Extract

https://www.kaggle.com/datasets/corrieaar/apartment-rental-offers-in-germany Datensatz: immo\_data.csv

in Produktion aus echter Bestandsdatenbank des Unternehmens

### Transform

#### Filterung

Mängel 1. / 2. Klasse:

* wenn eine der Spalten totalRent, serviceCharge, baseRent leer ist, dann aus den Werten der anderen Spalten berechnet
* Zeilen mit Nullwerten in wichtigen Spalten entfernen
* Nullwerte in diversen Spalten mit mean / median Wert auffüllen

```aspnet
df = df.dropna(subset=['obj_lotArea'])
df = df.dropna(subset=['obj_livingSpace'])
df = df.dropna(subset=['obj_purchasePrice'])
df = df.query('obj_lotArea != 0')
df = df.query('obj_livingSpace != 0')
df = df.query('obj_purchasePrice != 0')
df['pricepersqm_livingspace'] = df.obj_purchasePrice / df.obj_livingSpace
df['pricepersqm_lotarea'] = df.obj_purchasePrice / df.obj_lotArea
#display_dataframe(df, shorten=False)
#print(len(df.obj_scoutId.unique()))
df.obj_pricetrendbuy = df.obj_pricetrendbuy.fillna(df.median())
df.obj_pricetrend = df.obj_pricetrend.fillna(df.median())
#df.obj_lotArea = df.obj_lotArea.fillna(df.median())
df.obj_yearConstructed = df.obj_yearConstructed.fillna(df.median())
#df.obj_livingSpace = df.obj_livingSpace.fillna(df.median())
#df.obj_purchasePrice = df.obj_purchasePrice.fillna(df.median())
df.obj_noRooms = df.obj_noRooms.fillna(df.median())
df.obj_telekomUploadSpeed = df.obj_telekomUploadSpeed.fillna(df.median())
df.obj_telekomDownloadSpeed = df.obj_telekomDownloadSpeed.fillna(df.median())
```

Entfernung von Ausreißern abs 3% nach unten und oben:

* pricetrend
* totalRent
* serviceCharge
* baseRent
* livingSpace
* noRooms
* telekomUploadSpeed
* yearConstructed
* noParkSpaces

```aspnet
df = df[(np.abs(stats.zscore(df["pricetrend"])) < 3)]
#df = df[(np.abs(stats.zscore(df["totalRent"])) < 3)]
df = df[(np.abs(stats.zscore(df["serviceCharge"])) < 3)]
df = df[(np.abs(stats.zscore(df["baseRent"])) < 3)]
df = df[(np.abs(stats.zscore(df["livingSpace"])) < 3)]
df = df[(np.abs(stats.zscore(df["noRooms"])) < 3)]
df = df[(np.abs(stats.zscore(df["telekomUploadSpeed"])) < 3)]
df = df[(np.abs(stats.zscore(df["yearConstructed"])) < 3)]
#df = df.fillna(df.mean())
#df = df[(np.abs(stats.zscore(df["noParkSpaces"])) < 1.5)]
```

#### Harmonisierung

für alle Spalten mit Wahrheitswerten true mit 1 und false mit 0 ersetzen

```aspnet
df.balcony = df.balcony.replace({True: 1, False: 0})
df.hasKitchen = df.hasKitchen.replace({True: 1, False: 0})
df.cellar = df.cellar.replace({True: 1, False: 0})
df.lift = df.lift.replace({True: 1, False: 0})
df.garden = df.garden.replace({True: 1, False: 0})
```

#### Aggregation

Spalten entfernen: regio1, telekomTvOffer, telekomHybridUploadSpeed, newlyConst, picturecount, scoutId, geo\_bln, yearConstructedRange, houseNumber, geo\_krs, petsAllowed, street, streetPlain, baseRentRange, geo\_plz, thermalChar, numberOfFloors, noRoomsRange, livingSpaceRange, regio2, regio3, description, facilities, heatingCosts, energyEfficiencyClass, lastRefurbish, electricityBasePrice, electricityKwhPrice, date

```
df = df.drop(columns=['totalRent'])
df = df.drop(columns=['energyEfficiencyClass'])
df = df.drop(columns=['street'])
df = df.drop(columns=['streetPlain'])
df = df.drop(columns=['houseNumber'])
df = df.drop(columns=['geo_plz'])
df = df.drop(columns=['regio1'])
```

#### Anreicherung

Spalten hinzugefügt:

* longitude
* latitude
* qmPriceInEuroTotalRent = totalRent / livingSpace
* qmPriceInEuroServiceCharge = serviceCharge / livingSpace
* qmPriceInEuroBaseRent = baseRent / livingSpace
* long- und latitude mithilfe der Spalten via openstreatsmap abrufen und dann die Spalten entfernen
* Spalten: streetPlain, houseNumber, geo\_plz, regio2, regio1
* Hinzufügen einer eindeutigen fortlaufenden ID+

**m^2PreisinEuroWarm gleiche für kalt und nebenkosten**

### Load

Speichern als immoscout\_rent.csv

## immo\_data\_houses.csv

### Extract

https://www.kaggle.com/datasets/phanindraparashar/germany-housing-rent-and-price-data-set-apr-20 Datensatz: apr20\_price\_33\_col.csv

in Produktion über Immoscout API

rest ähnlich wie immo\_data.csv

## Breitbandversorgung&#x20;

### Extract

Datenabzug aus operativen Quellsystemen, i.d.R. automatisiert über Schnittstellen

von Regional Datenbank(https://www.regionalstatistik.de/genesis/online/logon) Datensätze: Tabelle Abfrage1 (2).csv

### Transform

#### Filterung

Mängel 1. Klasse

* 'Breitbandversorgung mit 50 Mbit/s in %' = "." entfernen und "," mit "." ersetzten
* 'Breitbandversorgung mit 100 Mbit/s in %' = "." entfernen und "," mit "." ersetzten
* 'Breitbandversorgung mit 1000 Mbit/s in %' = "." entfernen und "," mit "." ersetzten

```python
def clean_float(input):
    input = str(input).replace('.', '').replace(',', '.')
    return float(input)

df['Breitbandversorgung mit 50 Mbit/s in %'] = df['Breitbandversorgung mit 50 Mbit/s in %'].apply(
    cleanfuncs.clean_float)
df['Breitbandversorgung mit 100 Mbit/s in %'] = df['Breitbandversorgung mit 100 Mbit/s in %'].apply(
    cleanfuncs.clean_float)
df['Breitbandversorgung mit 1000 Mbit/s in %'] = df['Breitbandversorgung mit 1000 Mbit/s in %'].apply(
    cleanfuncs.clean_float)
```

#### Harmonisierung

umbenennen der Spalten:

* 'Kennziffer':'ags'
* 'Breitbandversorgung mit 50 Mbit/s in %': 'breitbandversorgung50MbitsProzent'
* 'Breitbandversorgung mit 100 Mbit/s in %': 'breitbandversorgung100MbitsProzent'
* 'Breitbandversorgung mit 1000 Mbit/s in %': 'breitbandversorgung1000MbitsProzent'

```python
df.rename(columns={'Kennziffer': 'ags',
                   'Breitbandversorgung mit 50 Mbit/s in %': 'breitbandversorgung50MbitsProzent',
                   'Breitbandversorgung mit 100 Mbit/s in %': 'breitbandversorgung100MbitsProzent',
                   'Breitbandversorgung mit 1000 Mbit/s in %': 'breitbandversorgung1000MbitsProzent'}, inplace=True)
```

#### Aggregation

Spalten entfernen: Raumeinheit, Aggregat, 'Breitbandversorgung mit 16 Mbit/s in %'

```python
df.drop(['Raumeinheit', 'Aggregat', 'Breitbandversorgung mit 16 Mbit/s in %'], axis=1, inplace=True)
```

#### Anreicherung

### Load

Speicherung als: breitbandversorgung20.csv

## bau\_einkommen\_insolvenz&#x20;

### Extract

Datenabzug aus operativen Quellsystemen, i.d.R. automatisiert über Schnittstellen

von Regional Datenbank (https://www.regionalstatistik.de/genesis/online/logon) Datensätze:

* Tabelle Abfrage1.csv
* Tabelle Abfrage1 (1).csv

### Transform

#### Filterung

für "Tabelle Abfrage1 (1).csv" Mängel 1. Klasse:

* Raumeinheit = von mehreren durch Komma getrennte Städtenamen nur den ersten behalten
* Baugenehmigungen für Wohnungen = "." entfernen und "," mit "." ersetzten
* Verbraucherinsolvenzverfahren = "." entfernen und "," mit "." ersetzten

<pre class="language-python"><code class="lang-python">def clean_float(input):
    input = str(input).replace('.', '').replace(',', '.')
    return float(input)

def clean_city(input: str):
    return input.split(',')[0]
<strong>
</strong><strong>df['Raumeinheit'] = df['Raumeinheit'].apply(cleanfuncs.clean_city)
</strong>df['Baugenehmigungen für Wohnungen'] = df['Baugenehmigungen für Wohnungen'].apply(cleanfuncs.clean_float)
df['Baulandpreise'] = df['Baulandpreise'].apply(cleanfuncs.clean_float)
</code></pre>

für "Tabelle Abfrage1.csv" Mängel 1. Klasse:

* Raumeinheit = von mehreren durch Komma getrennte Städtenamen nur den ersten behalten
* Haushaltseinkommen = "." entfernen und "," mit "." ersetzten
* Baulandpreise = "." entfernen und "," mit "." ersetzten

```python
def clean_float(input):
    input = str(input).replace('.', '').replace(',', '.')
    return float(input)

def clean_city(input: str):
    return input.split(',')[0]
    
df['Raumeinheit'] = df['Raumeinheit'].apply(cleanfuncs.clean_city)
df['Haushaltseinkommen'] = df['Haushaltseinkommen'].apply(cleanfuncs.clean_float)
df['Verbraucherinsolvenzverfahren'] = df['Verbraucherinsolvenzverfahren'].apply(cleanfuncs.clean_float)
```

#### Harmonisierung

für "Tabelle Abfrage1 (1).csv" Spalten umbenennen:

* 'Kennziffer': 'ags'
* 'Baugenehmigungen für Wohnungen': 'baugenehmigungenWohnungen'
* 'Baulandpreise': 'baulandpreise'

```python
df.rename(columns={'Kennziffer': 'ags',
                   'Baugenehmigungen für Wohnungen': 'baugenehmigungenWohnungen',
                   'Baulandpreise': 'baulandpreise'}, inplace=True)
```

für "Tabelle Abfrage1.csv" Spalten umbenennen:

* 'Kennziffer': 'ags'
* 'Haushaltseinkommen': 'haushaltseinkommen\_19'
* 'Verbraucherinsolvenzverfahren': 'verbraucherinsolvenzverfahren'

```python
df.rename(columns={'Kennziffer': 'ags', 'Haushaltseinkommen': 'haushaltseinkommen_19', 'Verbraucherinsolvenzverfahren': 'verbraucherinsolvenzverfahren'}, inplace=True)
```

#### Aggregation

für "Tabelle Abfrage1 (1).csv" Spalten entfernen: Raumeinheit, Aggregate

```python
df.drop(['Raumeinheit', 'Aggregat'], axis=1, inplace=True)
```

für "Tabelle Abfrage1.csv" Spalten entfernen: Arbeitsvolumen, Raumeinheit, Aggregate

```python
df.drop(['Arbeitsvolumen', 'Raumeinheit', 'Aggregat'], axis=1, inplace=True)
```

#### Anreicherung

bei Datensätze über den Spalte "ags" mergen (outer) für die Spalten "baugenehmigungenWohnungen" und "baulandpreise" Nullwerte mit den Durchschnittswerten der Spalten füllen

```python
import pandas as pd

df_paths = ['/Users/dannyneupauer/Downloads/daten/cleaned_data/baugenehmigungen20_baulandpreise20.csv',
            '/Users/dannyneupauer/Downloads/daten/cleaned_data/Haushaltseinkommen19_Insolvenzen20.csv']

dfs = list()
for path in df_paths:
    dfs.append(pd.read_csv(path, dtype={'ags': str}).set_index('ags'))


merged_df = dfs[0]
merged_df = merged_df.merge(dfs[1], on=['ags'], how='outer')

merged_df['baugenehmigungenWohnungen'] = merged_df['baugenehmigungenWohnungen'].fillna(merged_df['baugenehmigungenWohnungen'].mean())
merged_df['baulandpreise'] = merged_df['baulandpreise'].fillna(merged_df['baulandpreise'].mean())

print(merged_df.info())
```

### Load

Speichern als: merged\_bau\_einkommen\_insolvenz.csv

```python
merged_df.to_csv('/Users/dannyneupauer/Downloads/daten/cleaned_data/merged_bau_einkommen_insolvenz.csv')
```
